{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzwXjI8kWb2gXoj+r7XlDI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheshkumar145/DL_Theory/blob/main/DL_Assignment_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tWhat are the main tasks that autoencoders are used for?**\n",
        "\n",
        "**Ans:** Autoencoders are used to help reduce the noise in data. Through the process of compressing input data, encoding it, and then reconstructing it as an output, autoencoders allow you to reduce dimensionality and focus only on areas of real value."
      ],
      "metadata": {
        "id": "2Nuh5wLRpjFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.\tSuppose you want to train a classifier, and you have plenty of unlabeled training data but only a few thousand labeled instances. How can autoencoders help? How would you proceed?**\n",
        "\n",
        "**Ans:**  Autoencoders are considered an unsupervised learning technique since they donâ€™t need explicit labels to train on. But to be more precise they are self-supervised because they generate their own labels from the training data."
      ],
      "metadata": {
        "id": "2wb-j2pRphEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tIf an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder? How can you evaluate the performance of an autoencoder?**\n",
        "\n",
        "**Ans:**  yes, it is a good autoencoder. In practice, efficiency of autoencoder depends on how well it reconstructs and also on how robust it is to noise in different scenes.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZAtuVwEOpe8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.\tWhat are undercomplete and overcomplete autoencoders? What is the main risk of an excessively undercomplete autoencoder? What about the main risk of an overcomplete autoencoder?**\n",
        "\n",
        "**Ans:** \n",
        "\n",
        "**Undercomplete Autoencoder:**\n",
        "\n",
        "An undercomplete autoencoder is one in which the bottleneck layer has fewer hidden units than the input layer. In this case, the autoencoder must learn to compress the input data into a lower-dimensional representation before reconstructing it. The main risk of an excessively undercomplete autoencoder is that it may not be able to effectively compress the input data, leading to poor performance.\n",
        "\n",
        "**Overcomplete Autoencoder:**\n",
        "\n",
        "Overcomplete autoencoder is one in which the bottleneck layer has more hidden units than the input layer. In this case, the autoencoder has more capacity to learn a representation of the input data, but this can also be a risk, as an overcomplete autoencoder may overfit to the training data. This means that it may perform well on the training data but poorly on unseen data.\n"
      ],
      "metadata": {
        "id": "fo6pZB01pdEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.\tHow do you tie weights in a stacked autoencoder? What is the point of doing so?**\n",
        "\n",
        "**Ans:** To implement tying weights, we need to create a custom layer to tie weights between the layer using keras. This custom layer acts as a regular dense layer, but it uses the transposed weights of the encoder's dense layer, however having its own bias vector."
      ],
      "metadata": {
        "id": "SFlMGe3WpacP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.\tWhat is a generative model? Can you name a type of generative autoencoder?**\n",
        "\n",
        "**Ans:** A generative model includes the distribution of the data itself, and tells you how likely a given example is. For example, models that predict the next word in a sequence are typically generative models because they can assign a probability to a sequence of words.\n",
        "\n",
        "**Types:**\n",
        "\n",
        "* Gaussian mixture model\n",
        "\n",
        "* Bayesian network \n",
        "\n",
        "* Naive bayes \n",
        "\n",
        "* Autoregressive model\n",
        "\n",
        "* Boltzmann machine \n",
        "\n",
        "* Variational autoencoder\n",
        "\n",
        "* Flow-based generative model\n",
        "\n",
        "* Diffusion model"
      ],
      "metadata": {
        "id": "idD432YipY7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.\tWhat is a GAN? Can you name a few tasks where GANs can shine?**\n",
        "\n",
        "**Ans:** Generative adversarial networks (GANs) are an exciting recent innovation in machine learning. \n",
        "GANs are generative models: they create new data instances that resemble your training data. \n",
        "\n",
        "For example, GANs can create images that look like photographs of human faces, even though the faces don't belong to any real person"
      ],
      "metadata": {
        "id": "OnDuWsHFpXdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.\tWhat are the main difficulties when training GANs?**\n",
        "\n",
        "**Ans:** GANs are difficult to train. The reason they are difficult to train is that both the generator model and the discriminator model are trained simultaneously in a game. This means that improvements to one model come at the expense of the other model."
      ],
      "metadata": {
        "id": "BkE_r4_gpVks"
      }
    }
  ]
}